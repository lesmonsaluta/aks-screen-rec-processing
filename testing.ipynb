{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Editable code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the video file\n",
    "# cap = cv2.VideoCapture('sabio_data/video2.mp4')\n",
    "\n",
    "# # Dict for final values\n",
    "# final_timestamps = {'ts0, start' : '',\n",
    "# 'ts1, load service': '', \n",
    "# 'ts2, main screen' : '', \n",
    "# 'ts3, loading pickup' : '',\n",
    "# 'ts4, locking pickup' : '',\n",
    "# 'ts5, loading dropoff' : '',\n",
    "# 'ts6, locking dropoff' : '',\n",
    "# 'ts7, load promo' : '',\n",
    "# 'ts8, locking promo' : ''}\n",
    "\n",
    "# final_timestamps['ts0, start'] = '0:00:00)'\n",
    "\n",
    "\n",
    "\n",
    "# len = 0\n",
    "# active_frames = []\n",
    "# active_times_1 = []\n",
    "# pixel_value_list = []\n",
    "# times = []\n",
    "\n",
    "# # Loop through each frame of the video\n",
    "# while cap.isOpened():\n",
    "#     len +=1 \n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "#     # Define the pixel location to track\n",
    "#     x = 0\n",
    "#     y = 50\n",
    "    \n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "#     # Define the color threshold to track (in BGR format)\n",
    "#     color_threshold = (244, 151, 15)\n",
    "#     lower_color = (color_threshold[0]-10, color_threshold[1]-10, color_threshold[2]-10)\n",
    "#     upper_color = (color_threshold[0]+10, color_threshold[1]+10, color_threshold[2]+10)\n",
    "\n",
    "#     if ret:\n",
    "#         # Extract the pixel value at the desired location\n",
    "#         pixel_value = frame[y, x]\n",
    "#         pixel_value_list.append(pixel_value)\n",
    "#         times.append(len/fps)\n",
    "        \n",
    "        \n",
    "#         # Check if the pixel value falls within the color range\n",
    "#         # Timestamp 1\n",
    "#         if (pixel_value[0] in range(lower_color[0], upper_color[0])) and (pixel_value[1] in range(lower_color[1], upper_color[1])) and (pixel_value[2] in range(lower_color[2], upper_color[2])):\n",
    "#             # Get the timestamp of the current frame in milliseconds\n",
    "#             timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "#             # Convert the timestamp to minutes, seconds, and frames\n",
    "#             timestamp_min = int(timestamp_ms / (1000 * 60))\n",
    "#             timestamp_sec = int((timestamp_ms / 1000) % 60)\n",
    "#             timestamp_frame = int((timestamp_ms / 1000 * fps) % fps)\n",
    "#             # Print the timestamp in minutes, seconds, and frames\n",
    "#             print(f\"{timestamp_min:02d}:{timestamp_sec:02d}:{timestamp_frame:02d}\")\n",
    "#             print(f'frame number is {len}')\n",
    "#             active_frames.append(len)\n",
    "#             active_times_1.append(f'{timestamp_min}:{timestamp_sec}:{timestamp_ms}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "# for i in range(len-1):\n",
    "#     print(pixel_value_list[i], times[i])\n",
    "\n",
    "# print(active_frames)\n",
    "# print(active_times_1)\n",
    "# print(f'The last part of this sequence is: {active_times_1[-1]}')\n",
    "# final_timestamps['ts1, load service'] = active_times_1[-1]\n",
    "# print(final_timestamps)\n",
    "\n",
    "\n",
    "# # Release the video file\n",
    "# cap.release()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of editable code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the video file\n",
    "# cap = cv2.VideoCapture('sabio_data/video1.mp4')\n",
    "\n",
    "# # Define the pixel location to track\n",
    "# x = 10\n",
    "# y = 10\n",
    "\n",
    "# fps = 26.716792\n",
    "\n",
    "# # Define the color threshold to track (in BGR format)\n",
    "# color_threshold = (0,0,0)\n",
    "\n",
    "# len = 0\n",
    "\n",
    "# active_frames_1 = []\n",
    "# pixel_values = []\n",
    "\n",
    "\n",
    "# # Loop through each frame of the video\n",
    "# while cap.isOpened():\n",
    "#     len +=1 \n",
    "#     ret, frame = cap.read()\n",
    "#     if ret:\n",
    "#         # Extract the pixel value at the desired location\n",
    "#         pixel_value = frame[y, x]\n",
    "#         pixel_values.append(pixel_value)\n",
    "#         # Check if the pixel value falls within the color range\n",
    "#         if tuple(pixel_value) == color_threshold:\n",
    "#             # Get the timestamp of the current frame in milliseconds\n",
    "#             timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "#             # Convert the timestamp to minutes, seconds, and frames\n",
    "#             timestamp_min = int(timestamp_ms / (1000 * 60))\n",
    "#             timestamp_sec = int((timestamp_ms / 1000) % 60)\n",
    "#             timestamp_frame = int((timestamp_ms / 1000 * fps) % fps)\n",
    "#             # Print the timestamp in minutes, seconds, and frames\n",
    "#             print(f\"{timestamp_min:02d}:{timestamp_sec:02d}:{timestamp_frame:02d}\")\n",
    "#             print(f'frame number is {len}')\n",
    "#             active_frames_1.append(len)\n",
    "#     else:\n",
    "#         break\n",
    "# print(active_frames_1)\n",
    "# print(pixel_values)\n",
    "\n",
    "# # Release the video file\n",
    "# cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the video file\n",
    "# cap = cv2.VideoCapture('sabio_data/video2.mov')\n",
    "\n",
    "# # Define the pixel location to track\n",
    "# x = 100\n",
    "# y = 100\n",
    "\n",
    "# fps = 60\n",
    "\n",
    "# # Define the color threshold to track (in BGR format)\n",
    "# color_threshold = (0,0,0)\n",
    "\n",
    "# len = 0\n",
    "# active_frames = []\n",
    "\n",
    "\n",
    "# # Loop through each frame of the video\n",
    "# while cap.isOpened():\n",
    "#     len +=1 \n",
    "#     print(len)\n",
    "#     ret, frame = cap.read()\n",
    "#     if ret:\n",
    "#         # Extract the pixel value at the desired location\n",
    "#         pixel_value = frame[y, x]\n",
    "#         # Check if the pixel value falls within the color range\n",
    "#         if tuple(pixel_value) == color_threshold:\n",
    "#             # Get the timestamp of the current frame in milliseconds\n",
    "#             timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "#             # Convert the timestamp to minutes, seconds, and frames\n",
    "#             timestamp_min = int(timestamp_ms / (1000 * 60))\n",
    "#             timestamp_sec = int((timestamp_ms / 1000) % 60)\n",
    "#             timestamp_frame = int((timestamp_ms / 1000 * fps) % fps)\n",
    "#             # Print the timestamp in minutes, seconds, and frames\n",
    "#             print(f\"{timestamp_min:02d}:{timestamp_sec:02d}:{timestamp_frame:02d}\")\n",
    "#             print(f'frame number is {len}')\n",
    "#             active_frames.append(len)\n",
    "#     else:\n",
    "#         break\n",
    "# print(active_frames)\n",
    "# # Release the video file\n",
    "# cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# # Define the video file path\n",
    "# video_path = \"sabio_data/video2.mov\"\n",
    "\n",
    "# # Define the pixel location to check\n",
    "# x, y = 100, 200\n",
    "\n",
    "# # Open the video file\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# # Get the frames per second (fps) of the video\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# lower_color = np.array([0, 0, 0], dtype=np.uint8)\n",
    "# upper_color = np.array([0,0,0], dtype=np.uint8)\n",
    "\n",
    "\n",
    "# read_pixel = []\n",
    "\n",
    "# len = 0\n",
    "# # Loop through each frame of the video\n",
    "# while cap.isOpened():\n",
    "#     len += 1\n",
    "#     print(len)\n",
    "#     ret, frame = cap.read()\n",
    "#     if ret:\n",
    "#         # Extract the pixel value at the desired location\n",
    "#         pixel_value = frame[y, x]\n",
    "\n",
    "#         # Check if the pixel value falls within the color range\n",
    "#         if cv2.inRange(frame, lower_color, upper_color).any():\n",
    "#             # Get the timestamp of the current frame in milliseconds\n",
    "#             timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "#             # Convert the timestamp to minutes, seconds, and frames\n",
    "#             timestamp_min = int(timestamp_ms / (1000 * 60))\n",
    "#             timestamp_sec = int((timestamp_ms / 1000) % 60)\n",
    "#             timestamp_frame = int((timestamp_ms / 1000 * fps) % fps)\n",
    "#             # Print the timestamp in minutes, seconds, and frames\n",
    "#             print(f\"{timestamp_min:02d}:{timestamp_sec:02d}:{timestamp_frame:02d}\")\n",
    "#             read_pixel.append(len)\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "# print(f'total frames: {len}')\n",
    "# print(f'read_frames: {read_pixel}')\n",
    "# # Release the video file\n",
    "# cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the video file\n",
    "# cap = cv2.VideoCapture('sabio_data/video3.mov')\n",
    "\n",
    "# # Define the pixel location to track\n",
    "# x = 100\n",
    "# y = 100\n",
    "\n",
    "# fps = 60\n",
    "\n",
    "# # Define the color threshold to track (in BGR format)\n",
    "# color_threshold = (108, 67, 34)\n",
    "\n",
    "# len = 0\n",
    "# active_frames = []\n",
    "\n",
    "\n",
    "# # Loop through each frame of the video\n",
    "# while cap.isOpened():\n",
    "#     len +=1 \n",
    "#     print(len)\n",
    "#     ret, frame = cap.read()\n",
    "#     if ret:\n",
    "#         # Extract the pixel value at the desired location\n",
    "#         pixel_value = frame[y, x]\n",
    "#         print(pixel_value)\n",
    "#         # Check if the pixel value falls within the color range\n",
    "#         if tuple(pixel_value) == color_threshold:\n",
    "#             # Get the timestamp of the current frame in milliseconds\n",
    "#             timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "#             # Convert the timestamp to minutes, seconds, and frames\n",
    "#             timestamp_min = int(timestamp_ms / (1000 * 60))\n",
    "#             timestamp_sec = int((timestamp_ms / 1000) % 60)\n",
    "#             timestamp_frame = int((timestamp_ms / 1000 * fps) % fps)\n",
    "#             # Print the timestamp in minutes, seconds, and frames\n",
    "#             print(f\"{timestamp_min:02d}:{timestamp_sec:02d}:{timestamp_frame:02d}\")\n",
    "#             print(f'frame number is {len}')\n",
    "#             active_frames.append(len)\n",
    "#     else:\n",
    "#         break\n",
    "# print(active_frames)\n",
    "# # Release the video file\n",
    "# cap.release()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dict for final values\n",
    "final_timestamps = {\n",
    "'ts1, load service': {'start' : '', 'end' : ''}, \n",
    "'ts2, main screen' : {'start' : '', 'end' : ''}, \n",
    "'ts3, loading pickup' : {'start' : '', 'end' : ''},\n",
    "'ts4, locking pickup' : {'start' : '', 'end' : ''},\n",
    "'ts5, loading dropoff' : {'start' : '', 'end' : ''},\n",
    "'ts6, locking dropoff' : {'start' : '', 'end' : ''},\n",
    "'ts7, load promo' : {'start' : '', 'end' : ''},\n",
    "'ts8, locking promo' : {'start' : '', 'end' : ''}\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts1(cap, coords, color_threshold):\n",
    "\n",
    "    len = 0\n",
    "    active_frames_1 = []\n",
    "    active_times_1 = []\n",
    "    pixel_value_list = []\n",
    "    times = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Loop through each frame of the video\n",
    "    while cap.isOpened():\n",
    "        len +=1 \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        \n",
    "        # Define the pixel location to track\n",
    "        # x = 10\n",
    "        # y = 50\n",
    "        (x, y) = coords\n",
    "        \n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # Define the color threshold to track (in BGR format)\n",
    "        # color_threshold = (244, 151, 15)\n",
    "        lower_color = (color_threshold[0]-10, color_threshold[1]-10, color_threshold[2]-10)\n",
    "        upper_color = (color_threshold[0]+10, color_threshold[1]+10, color_threshold[2]+10)\n",
    "    \n",
    "        if ret:\n",
    "            # Extract the pixel value at the desired location\n",
    "            pixel_value = frame[y, x]\n",
    "            pixel_value_list.append(pixel_value)\n",
    "            times.append(len/fps)\n",
    "            \n",
    "            \n",
    "            # Check if the pixel value falls within the color range\n",
    "            # Timestamp 1\n",
    "            if (pixel_value[0] in range(lower_color[0], upper_color[0])) and (pixel_value[1] in range(lower_color[1], upper_color[1])) and (pixel_value[2] in range(lower_color[2], upper_color[2])):\n",
    "                # print(f'frame {len} : pixel value : {pixel_value}')\n",
    "                # Get the timestamp of the current frame in milliseconds\n",
    "                timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                # Convert the timestamp to minutes, seconds, and frames\n",
    "                timestamp_min = int(timestamp_ms / (1000 * 60))\n",
    "                timestamp_sec = int((timestamp_ms / 1000) % 60)\n",
    "                timestamp_frame = int((timestamp_ms / 1000 * fps) % fps)\n",
    "                # Print the timestamp in minutes, seconds, and frames\n",
    "                # print(f\"{timestamp_min:02d}:{timestamp_sec:02d}:{timestamp_frame:02d}\")\n",
    "                # print(f'frame number is {len}')\n",
    "                active_frames_1.append(len)\n",
    "                active_times_1.append(f'{timestamp_min}:{timestamp_sec}:{str(timestamp_frame/fps)[2:6]}')\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # for i in range(len-1):\n",
    "    #     print(pixel_value_list[i], times[i])\n",
    "    \n",
    "    # print(active_frames)\n",
    "    # print(active_times_1)\n",
    "    # print(f'The last part of this sequence is: {active_times_1[-1]}')\n",
    "    #final_timestamps['ts0, start']['end'] = active_times_1[-1]\n",
    "    final_timestamps['ts1, load service']['start'] =  active_times_1[-1]\n",
    "    \n",
    "    # print(final_timestamps)\n",
    "    \n",
    "    \n",
    "    # Release the video file\n",
    "    cap.release()\n",
    "    return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts2(cap, coords, color_threshold):\n",
    "\n",
    "    len = 0\n",
    "    active_frames_2 = []\n",
    "    active_times_2 = []\n",
    "    pixel_value_list = []\n",
    "    times = []\n",
    "    \n",
    "    # Loop through each frame of the video\n",
    "    while cap.isOpened():\n",
    "        len +=1 \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        \n",
    "        # Define the pixel location to track\n",
    "        # x = 81\n",
    "        # y = 406\n",
    "        (x,y) = coords\n",
    "        \n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # Define the color threshold to track (in BGR format)\n",
    "        # color_threshold = (146, 84, 45)\n",
    "        lower_color = (color_threshold[0]-10, color_threshold[1]-10, color_threshold[2]-10)\n",
    "        upper_color = (color_threshold[0]+10, color_threshold[1]+10, color_threshold[2]+10)\n",
    "    \n",
    "        if ret:\n",
    "            # Extract the pixel value at the desired location\n",
    "            pixel_value = frame[y, x]\n",
    "            pixel_value_list.append(pixel_value)\n",
    "            times.append(len/fps)\n",
    "            # # Debugger tool\n",
    "            # timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            # print(len/fps, pixel_value)\n",
    "            \n",
    "            \n",
    "            # Check if the pixel value falls within the color range\n",
    "            # Timestamp 1\n",
    "            if (pixel_value[0] in range(lower_color[0], upper_color[0])) and (pixel_value[1] in range(lower_color[1], upper_color[1])) and (pixel_value[2] in range(lower_color[2], upper_color[2])):\n",
    "                # print(f'frame {len} : pixel value : {pixel_value}')\n",
    "                # Get the timestamp of the current frame in milliseconds\n",
    "                timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                # Convert the timestamp to minutes, seconds, and frames\n",
    "                timestamp_min = int(timestamp_ms / (1000 * 60))\n",
    "                timestamp_sec = int((timestamp_ms / 1000) % 60)\n",
    "                timestamp_frame = int((timestamp_ms / 1000 * fps) % fps)\n",
    "                # Print the timestamp in minutes, seconds, and frames\n",
    "                # print(f\"{timestamp_min:02d}:{timestamp_sec:02d}:{timestamp_frame:02d}\")\n",
    "                # print(f'frame number is {len}')\n",
    "                active_frames_2.append(len)\n",
    "                active_times_2.append(f'{timestamp_min}:{timestamp_sec}:{str(timestamp_frame/fps)[2:6]}')\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # for i in range(len-1):\n",
    "    #     print(pixel_value_list[i], times[i])\n",
    "    \n",
    "    # print(active_frames)\n",
    "    # print(active_times_1)\n",
    "    # print(f'The last part of this sequence is: {active_times_1[-1]}')\n",
    "    final_timestamps['ts1, load service']['end'] = active_times_2[1]\n",
    "    final_timestamps['ts2, main screen']['start'] = active_times_2[-1]\n",
    "    # print(final_timestamps)\n",
    "    \n",
    "    \n",
    "    # Release the video file\n",
    "    cap.release()\n",
    "    return None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"sabio_data/video1.mp4\"\n"
     ]
    }
   ],
   "source": [
    "def get_ts3(cap):\n",
    "\n",
    "    len = 0\n",
    "    active_frames_3 = []\n",
    "    active_times_3 = []\n",
    "    pixel_value_list = []\n",
    "    times = []\n",
    "    \n",
    "    # Loop through each frame of the video\n",
    "    while cap.isOpened():\n",
    "        len +=1 \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        \n",
    "        # Define the pixel location to track\n",
    "        x = 191\n",
    "        y = 730\n",
    "        \n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # Define the color threshold to track (in BGR format)\n",
    "        color_threshold = (249, 245, 247)\n",
    "        lower_color = (color_threshold[0]-10, color_threshold[1]-10, color_threshold[2]-10)\n",
    "        upper_color = (color_threshold[0]+10, color_threshold[1]+10, color_threshold[2]+10)\n",
    "    \n",
    "        if ret:\n",
    "            # Extract the pixel value at the desired location\n",
    "            pixel_value = frame[y, x]\n",
    "            pixel_value_list.append(pixel_value)\n",
    "            times.append(len/fps)\n",
    "            # Debugger tool\n",
    "            # timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            # print(len/fps, pixel_value)\n",
    "            \n",
    "            \n",
    "            # Check if the pixel value falls within the color range\n",
    "            # Timestamp 1\n",
    "            if (pixel_value[0] in range(lower_color[0], upper_color[0])) and (pixel_value[1] in range(lower_color[1], upper_color[1])) and (pixel_value[2] in range(lower_color[2], upper_color[2])):\n",
    "                print(len/fps, pixel_value)\n",
    "                # print(f'frame {len} : pixel value : {pixel_value}')\n",
    "                # Get the timestamp of the current frame in milliseconds\n",
    "                timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                # Convert the timestamp to minutes, seconds, and frames\n",
    "                timestamp_min = int(timestamp_ms / (1000 * 60))\n",
    "                timestamp_sec = int((timestamp_ms / 1000) % 60)\n",
    "                timestamp_frame = int((timestamp_ms / 1000 * fps) % fps)\n",
    "                # Print the timestamp in minutes, seconds, and frames\n",
    "                # print(f\"{timestamp_min:02d}:{timestamp_sec:02d}:{timestamp_frame:02d}\")\n",
    "                # print(f'frame number is {len}')\n",
    "                active_frames_3.append(len)\n",
    "                active_times_3.append(f'{timestamp_min}:{timestamp_sec}:{str(timestamp_frame/fps)[2:6]}')\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # for i in range(len-1):\n",
    "    #     print(pixel_value_list[i], times[i])\n",
    "    \n",
    "    # print(active_frames)\n",
    "    \n",
    "    print(active_times_3)\n",
    "    # print(f'The last part of this sequence is: {active_times_1[-1]}')\n",
    "    \n",
    "    # final_timestamps['ts1, load service']['end'] = active_times_3[1]\n",
    "    # final_timestamps['ts2, main screen']['start'] = active_times_3[-1]\n",
    "    \n",
    "    # print(final_timestamps)\n",
    "    \n",
    "    \n",
    "    # Release the video file\n",
    "    cap.release()\n",
    "    return None\n",
    "    \n",
    "\n",
    "get_ts3(cv2.VideoCapture('sabio_data/video1.mp4'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"sabio_data/video1.mp4\"\n"
     ]
    }
   ],
   "source": [
    "def get_ts4(cap):\n",
    "\n",
    "    len = 0\n",
    "    active_frames_4 = []\n",
    "    active_times_4 = []\n",
    "    pixel_value_list = []\n",
    "    times = []\n",
    "    \n",
    "    # Loop through each frame of the video\n",
    "    while cap.isOpened():\n",
    "        len +=1 \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        \n",
    "        # Define the pixel location to track\n",
    "        x = 191\n",
    "        y = 730\n",
    "        \n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # Define the color threshold to track (in BGR format)\n",
    "        color_threshold = (249, 245, 247)\n",
    "        lower_color = (color_threshold[0]-10, color_threshold[1]-10, color_threshold[2]-10)\n",
    "        upper_color = (color_threshold[0]+10, color_threshold[1]+10, color_threshold[2]+10)\n",
    "    \n",
    "        if ret:\n",
    "            # Extract the pixel value at the desired location\n",
    "            pixel_value = frame[y, x]\n",
    "            pixel_value_list.append(pixel_value)\n",
    "            times.append(len/fps)\n",
    "            # Debugger tool\n",
    "            # timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            # print(len/fps, pixel_value)\n",
    "            \n",
    "            \n",
    "            # Check if the pixel value falls within the color range\n",
    "            # Timestamp 1\n",
    "            if (pixel_value[0] in range(lower_color[0], upper_color[0])) and (pixel_value[1] in range(lower_color[1], upper_color[1])) and (pixel_value[2] in range(lower_color[2], upper_color[2])):\n",
    "                print(len/fps, pixel_value)\n",
    "                # print(f'frame {len} : pixel value : {pixel_value}')\n",
    "                # Get the timestamp of the current frame in milliseconds\n",
    "                timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                # Convert the timestamp to minutes, seconds, and frames\n",
    "                timestamp_min = int(timestamp_ms / (1000 * 60))\n",
    "                timestamp_sec = int((timestamp_ms / 1000) % 60)\n",
    "                timestamp_frame = int((timestamp_ms / 1000 * fps) % fps)\n",
    "                # Print the timestamp in minutes, seconds, and frames\n",
    "                # print(f\"{timestamp_min:02d}:{timestamp_sec:02d}:{timestamp_frame:02d}\")\n",
    "                # print(f'frame number is {len}')\n",
    "                active_frames_4.append(len)\n",
    "                active_times_4.append(f'{timestamp_min}:{timestamp_sec}:{str(timestamp_frame/fps)[2:6]}')\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # for i in range(len-1):\n",
    "    #     print(pixel_value_list[i], times[i])\n",
    "    \n",
    "    # print(active_frames)\n",
    "    \n",
    "    print(active_times_4)\n",
    "    # print(f'The last part of this sequence is: {active_times_1[-1]}')\n",
    "    \n",
    "    # final_timestamps['ts1, load service']['end'] = active_times_3[1]\n",
    "    # final_timestamps['ts2, main screen']['start'] = active_times_3[-1]\n",
    "    \n",
    "    # print(final_timestamps)\n",
    "    \n",
    "    \n",
    "    # Release the video file\n",
    "    cap.release()\n",
    "    return None\n",
    "    \n",
    "\n",
    "get_ts3(cv2.VideoCapture('sabio_data/video1.mp4'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts6(cap, coords, color_threshold):\n",
    "\n",
    "    len = 0\n",
    "    active_frames_6 = []\n",
    "    active_times_6 = []\n",
    "    pixel_value_list = []\n",
    "    times = []\n",
    "    \n",
    "    \n",
    "\n",
    "    # Loop through each frame of the video\n",
    "    while cap.isOpened():\n",
    "        len +=1 \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        \n",
    "        # Define the pixel location to track\n",
    "        # x = 10\n",
    "        # y = 50\n",
    "        (x, y) = coords\n",
    "        \n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # Define the color threshold to track (in BGR format)\n",
    "        # color_threshold = (244, 151, 15)\n",
    "        lower_color = (color_threshold[0]-10, color_threshold[1]-10, color_threshold[2]-10)\n",
    "        upper_color = (color_threshold[0]+10, color_threshold[1]+10, color_threshold[2]+10)\n",
    "    \n",
    "        if ret:\n",
    "            # Extract the pixel value at the desired location\n",
    "            pixel_value = frame[y, x]\n",
    "            pixel_value_list.append(pixel_value)\n",
    "            times.append(len/fps)\n",
    "            timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            #print(f'time {len/fps} : pixel value : {pixel_value}')\n",
    "            \n",
    "            \n",
    "            # Check if the pixel value falls within the color range\n",
    "            # Timestamp 1\n",
    "            if (pixel_value[0] in range(lower_color[0], upper_color[0])) and (pixel_value[1] in range(lower_color[1], upper_color[1])) and (pixel_value[2] in range(lower_color[2], upper_color[2])):\n",
    "                \n",
    "                # Get the timestamp of the current frame in milliseconds\n",
    "                timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                # Convert the timestamp to minutes, seconds, and frames\n",
    "                timestamp_min = int(timestamp_ms / (1000 * 60))\n",
    "                timestamp_sec = int((timestamp_ms / 1000) % 60)\n",
    "                timestamp_frame = int((timestamp_ms / 1000 * fps) % fps)\n",
    "                # Print the timestamp in minutes, seconds, and frames\n",
    "                #print(f\"{timestamp_min:02d}:{timestamp_sec:02d}:{timestamp_frame:02d}\")\n",
    "                # print(f'frame number is {len}')\n",
    "                active_frames_6.append(len)\n",
    "                active_times_6.append(f'{timestamp_min}:{timestamp_sec}:{str(timestamp_frame/fps)[2:6]}')\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \n",
    "    def get_2nd (str):\n",
    "        return int(str.split(':')[1])\n",
    "    \n",
    "    cluster = 1\n",
    "    cluster_1 = []\n",
    "    cluster_2 = []\n",
    "    cluster_3 = []\n",
    "    for idx, val in enumerate(active_times_6):\n",
    "        if idx > 0:\n",
    "            if get_2nd(active_times_6[idx]) - get_2nd(active_times_6[idx-1]) > 5:\n",
    "                cluster +=1\n",
    "        #print(f'{get_2nd(active_times_6[idx])}, {get_2nd(active_times_6[idx-1])}, {get_2nd(active_times_6[idx]) - get_2nd(active_times_6[idx-1])}')\n",
    "        cluster_name = 'cluster_' + str(cluster)\n",
    "        eval(cluster_name).append(val)\n",
    "        \n",
    "        \n",
    "        #print(get_2nd(active_times_6[idx]))\n",
    "        #print(get_2nd(active_times_6[idx]) - get_2nd(active_times_6[idx]))\n",
    "        \n",
    "        #print(cluster)\n",
    "    \n",
    "    #print(cluster_1, cluster_2, cluster_3)\n",
    "    \n",
    "    print(f\"cluster2 is {cluster_2}\")\n",
    "    print(f\"cluster3 is {cluster_3}\")\n",
    "    final_timestamps['ts6, locking dropoff']['end'] = cluster_2[1]\n",
    "    final_timestamps['ts8, locking promo']['end'] = cluster_3[1]\n",
    "    # for i in range(len-1):\n",
    "    #     print(pixel_value_list[i], times[i])\n",
    "    \n",
    "    # print(active_frames)\n",
    "    # print(active_times_1)\n",
    "    # print(f'The last part of this sequence is: {active_times_1[-1]}')\n",
    "    #final_timestamps['ts0, start']['end'] = active_times_1[-1]\n",
    "    #final_timestamps['ts6, locking dropoff']['end'] =  active_times_1[-1]\n",
    "    \n",
    "    # print(final_timestamps)\n",
    "    \n",
    "    \n",
    "    # Release the video file\n",
    "    cap.release()\n",
    "    return None\n",
    "\n",
    "\n",
    "#print(final_timestamps['ts6, locking dropoff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n"
     ]
    }
   ],
   "source": [
    "print([x for x in range(1,27)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing final run\n",
      "final run 1\n",
      "we are in video 1\n",
      "final run 2\n",
      "we are in video 2\n",
      "final run 3\n",
      "we are in video 3\n",
      "final run 4\n",
      "we are in video 4\n",
      "final run 5\n",
      "we are in video 5\n",
      "final run 6\n",
      "we are in video 6\n",
      "final run 7\n",
      "we are in video 7\n",
      "final run 8\n",
      "we are in video 8\n",
      "final run 9\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[990], line 40\u001b[0m\n\u001b[1;32m     36\u001b[0m video_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m4_14_data/vid\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.mp4\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[39m# video path, coords, color_threshold\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m get_ts1(cv2\u001b[39m.\u001b[39;49mVideoCapture(video_path), (\u001b[39m10\u001b[39;49m,\u001b[39m50\u001b[39;49m), (\u001b[39m244\u001b[39;49m, \u001b[39m151\u001b[39;49m, \u001b[39m15\u001b[39;49m))\n\u001b[1;32m     41\u001b[0m get_ts2(cv2\u001b[39m.\u001b[39mVideoCapture(video_path), (\u001b[39m81\u001b[39m, \u001b[39m406\u001b[39m), (\u001b[39m146\u001b[39m, \u001b[39m84\u001b[39m, \u001b[39m45\u001b[39m))\n\u001b[1;32m     42\u001b[0m \u001b[39m#get_ts6(cv2.VideoCapture(video_path), (440, 800), (244, 151, 15))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[984], line 63\u001b[0m, in \u001b[0;36mget_ts1\u001b[0;34m(cap, coords, color_threshold)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# for i in range(len-1):\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m#     print(pixel_value_list[i], times[i])\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39m# print(f'The last part of this sequence is: {active_times_1[-1]}')\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39m#final_timestamps['ts0, start']['end'] = active_times_1[-1]\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m final_timestamps[\u001b[39m'\u001b[39m\u001b[39mts1, load service\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mstart\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m  active_times_1[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[1;32m     65\u001b[0m \u001b[39m# print(final_timestamps)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[39m# Release the video file\u001b[39;00m\n\u001b[1;32m     69\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ts1_start = []\n",
    "ts1_end = []\n",
    "ts2_start = []\n",
    "ts2_end = []\n",
    "ts3_start = []\n",
    "ts3_end = []\n",
    "ts4_start = []\n",
    "ts4_end = []\n",
    "ts5_start = []\n",
    "ts5_end = []\n",
    "ts6_start = []\n",
    "ts6_end = []\n",
    "ts7_start = []\n",
    "ts7_end = []\n",
    "ts8_start = []\n",
    "ts8_end = []\n",
    "\n",
    "\n",
    "print('initializing final run')\n",
    "\n",
    "for i in range(1,27):\n",
    "    print(f\"final run {i}\")\n",
    "    # Dict for final values\n",
    "    final_timestamps = {\n",
    "    'ts1, load service': {'start' : '', 'end' : ''}, \n",
    "    'ts2, main screen' : {'start' : '', 'end' : ''}, \n",
    "    'ts3, loading pickup' : {'start' : '', 'end' : ''},\n",
    "    'ts4, locking pickup' : {'start' : '', 'end' : ''},\n",
    "    'ts5, loading dropoff' : {'start' : '', 'end' : ''},\n",
    "    'ts6, locking dropoff' : {'start' : '', 'end' : ''},\n",
    "    'ts7, load promo' : {'start' : '', 'end' : ''},\n",
    "    'ts8, locking promo' : {'start' : '', 'end' : ''}\n",
    "    }\n",
    "    \n",
    "    should_print=False\n",
    "    video_path = f'4_14_data/vid{i}.mp4'\n",
    "\n",
    "\n",
    "    # video path, coords, color_threshold\n",
    "    get_ts1(cv2.VideoCapture(video_path), (10,50), (244, 151, 15))\n",
    "    get_ts2(cv2.VideoCapture(video_path), (81, 406), (146, 84, 45))\n",
    "    #get_ts6(cv2.VideoCapture(video_path), (440, 800), (244, 151, 15))\n",
    "        \n",
    "\n",
    "    k = 1\n",
    "    for key in final_timestamps:\n",
    "        add_to_start = eval(f'ts{k}_start')\n",
    "        add_to_end = eval(f'ts{k}_end')\n",
    "        \n",
    "        add_to_start.append(final_timestamps[key]['start'])\n",
    "        add_to_end.append(final_timestamps[key]['end'])\n",
    "        k += 1\n",
    "    print(f'we are in video {i}')\n",
    "\n",
    "\n",
    "    \n",
    "ts_lists = [ts1_start, ts1_end, ts2_start, ts2_end, ts3_start, ts3_end, ts4_start, ts4_end,\n",
    "            ts5_start, ts5_end, ts6_start, ts6_end, ts7_start, ts7_end, ts8_start, ts8_end]\n",
    "\n",
    "for i, ts_list in enumerate(ts_lists):\n",
    "    print(f\"ts{i+1}_start: {ts_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0:10:2699']\n",
      "['0:11:4626']\n",
      "['0:16:1156']\n",
      "['']\n",
      "['']\n",
      "['']\n",
      "['']\n",
      "['']\n",
      "['']\n",
      "['']\n",
      "['']\n",
      "['0:32:1927']\n",
      "['']\n",
      "['']\n",
      "['']\n",
      "['0:47:0771']\n"
     ]
    }
   ],
   "source": [
    "ts_lists = [ts1_start, ts1_end, ts2_start, ts2_end, ts3_start, ts3_end, ts4_start, ts4_end,\n",
    "            ts5_start, ts5_end, ts6_start, ts6_end, ts7_start, ts7_end, ts8_start, ts8_end]\n",
    "\n",
    "for list in ts_lists:\n",
    "    if len(list) > 0:\n",
    "        print(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = f'4_13_wifi/vid{1}.mp4'\n",
    "\n",
    "# get_ts1(cv2.VideoCapture(video_path), (10,50), (244, 151, 15))\n",
    "\n",
    "\n",
    "# ts1_start = []\n",
    "# ts1_end = []\n",
    "# ts2_start = []\n",
    "# ts2_end = []\n",
    "# ts3_start = []\n",
    "# ts3_end = []\n",
    "# ts4_start = []\n",
    "# ts4_end = []\n",
    "# ts5_start = []\n",
    "# ts5_end = []\n",
    "# ts6_start = []\n",
    "# ts6_end = []\n",
    "# ts7_start = []\n",
    "# ts7_end = []\n",
    "# ts8_start = []\n",
    "# ts8_end = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# i = 1\n",
    "# for key in final_timestamps:\n",
    "#     print(f'{key} : {final_timestamps[key]}')\n",
    "#     add_to_start = eval(f'ts{i}_start')\n",
    "#     add_to_end = eval(f'ts{i}_end')\n",
    "    \n",
    "#     add_to_start.append(final_timestamps[key]['start'])\n",
    "#     add_to_end.append(final_timestamps[key]['end'])\n",
    "\n",
    "# print(ts1_start)\n",
    "# print(ts1_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts1_start</th>\n",
       "      <th>ts1_end</th>\n",
       "      <th>ts2_start</th>\n",
       "      <th>ts6_end</th>\n",
       "      <th>ts8_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0:10:2699</td>\n",
       "      <td>0:11:4626</td>\n",
       "      <td>0:16:1156</td>\n",
       "      <td>0:32:1927</td>\n",
       "      <td>0:47:0771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts1_start    ts1_end  ts2_start    ts6_end    ts8_end\n",
       "0  0:10:2699  0:11:4626  0:16:1156  0:32:1927  0:47:0771"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'ts1_start': ts1_start, 'ts1_end': ts1_end, 'ts2_start': ts2_start,\n",
    "        'ts6_end': ts6_end,\n",
    "        'ts8_end': ts8_end}\n",
    "\n",
    "# for key in data.keys():\n",
    "#         print(data[key])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(cell):\n",
    "    splitted = cell.split(':')\n",
    "    mins = splitted[0]\n",
    "    if int((splitted)[1]) < 10:\n",
    "        secs = f'0' + splitted[1]\n",
    "    else:\n",
    "        secs = splitted[1]\n",
    "    frames = int(round((int(splitted[2]) * 27.441254)//1, 2))\n",
    "    print(int(str(frames)[0:2]))\n",
    "    if int(str(frames)[0:2]) > 27.441254:\n",
    "        frames = '0' + str(frames)\n",
    "    else:\n",
    "        frames = str(frames)\n",
    "    return f'00:{secs}:{(frames)}'[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "12\n",
      "31\n",
      "52\n",
      "21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts1_start</th>\n",
       "      <th>ts1_end</th>\n",
       "      <th>ts2_start</th>\n",
       "      <th>ts6_end</th>\n",
       "      <th>ts8_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:10:07</td>\n",
       "      <td>00:11:12</td>\n",
       "      <td>00:16:03</td>\n",
       "      <td>00:32:05</td>\n",
       "      <td>00:47:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ts1_start   ts1_end ts2_start   ts6_end   ts8_end\n",
       "0  00:10:07  00:11:12  00:16:03  00:32:05  00:47:21"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.applymap(get_frames)\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
